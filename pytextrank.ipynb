{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize News articles from main page of a news website\n",
    "## Spacy Library\n",
    "Decided to switch to Spacy which is better instead of flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Ideas and How the results can be used\n",
    "* Sift through news sites  \n",
    "* filter news that mentions name of brand  \n",
    "* summarize article to get gist of news\n",
    "* do a timeline of sentiment using sentiment analysis\n",
    "* Regression of sentiment on any other factor\n",
    "* STOCK price vs Sentiment in news\n",
    "* number of sales and sentiment in reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sift through news articles using python library *newspaper3k*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "from newspaper import Article\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716\n"
     ]
    }
   ],
   "source": [
    "# build newspaper object \n",
    "wsj_paper = newspaper.build('https://www.cnn.com/', memoize_articles=False)\n",
    "print(len(wsj_paper.articles)) # number of articles on the fron page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls of all the articles and store in a list\n",
    "urls = []\n",
    "for article in wsj_paper.articles:\n",
    "    urls.append(article.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts contains all articles in CNN front page that mention Apple\n",
    "texts  = []\n",
    "for u in urls[:200]:\n",
    "    article = Article(u)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    if \"Apple\" in article.text:\n",
    "        texts.append(article.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command in its own cell, otherwise won't work\n",
    "#pip install -U spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of stopwords, import punctuation and add newline to it\n",
    "\n",
    "stopwords=list(STOP_WORDS)\n",
    "from string import punctuation\n",
    "punctuation=punctuation+ '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to do below command for a better trained dictionary en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for finding score of each word in a sentence, we use pytextrank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x14103aa90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add PyTextRank to the spaCy pipeline (do it once only otherwise it gives error)\n",
    "nlp.add_pipe(\"textrank\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'textrank']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names # check if textrank got added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for cleaning sentences before applying textrank that will help later when calculating score of sentences.\n",
    "\n",
    "def clean_text(t):\n",
    "    return re.sub(\"[^a-zA-Z\\.\\?\\!]\", \" \",t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in set of sentences or a text block(t) and gives dictionay of score of keyphrases\n",
    "def dict_kphrase(t):\n",
    "    dict_kp = dict() \n",
    "    doc = nlp(clean_text)\n",
    "    for phrase in doc._.phrases:\n",
    "        dict_kp[phrase.text]=phrase.rank\n",
    "    return dict_kp\n",
    "        #myList.append((phrase.rank, phrase.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nadiakhalil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# for spliting text into sentences we will use nltk\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gives dictionary for calculating score of each sentence using keyphrase scores. Takes in t=text of\n",
    "# sentences (sentences) and a dictionary (d) of scores of keyphrases of that text (t)\n",
    "def score(t,d):\n",
    "    score_dict = dict()\n",
    "    for sent in t:\n",
    "        score_dict[sent] = 0\n",
    "        for kphrase in d.keys():\n",
    "            if kphrase in sent:\n",
    "                score_dict[sent]+= d[kphrase][0]\n",
    "    return score_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The idea is to consider n highest ranked sentences as summary of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeHighest = nlargest(3, score_dict, key = score_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' CNN  The cast and producers of Apple s  Ted Lasso  scored a major W during Tuesday s Emmy nominations and broke a record in the process.', 'With its    nominations   Ted Lasso  became the most nominated freshman comedy in Emmy history  besting the    nominations  Glee  earned in      for its first season.', 'The nods earned by  Ted Lasso  included best comedy  best lead actor  Jason Sudeikis  and a number of accolades for the show s supporting cast.']\n"
     ]
    }
   ],
   "source": [
    "print(ThreeHighest) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
